{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dbd5cd-c7b1-444f-a37b-ff5f453fc49f",
   "metadata": {},
   "source": [
    "## Common LLM applications\n",
    "\n",
    "The goal of this section is to get your feet wet with several LLM applications and to show how easy it can be to get started with LLMs.\n",
    "\n",
    "As you go through the examples, note the datasets, models, APIs, and options used.  These simple examples can be starting points when you need to build your own application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f16b938-472d-4ab4-9dfb-b7cc45083f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses==0.0.53 in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (0.0.53)\n",
      "Requirement already satisfied: regex in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (from sacremoses==0.0.53) (2023.10.3)\n",
      "Requirement already satisfied: six in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (from sacremoses==0.0.53) (1.16.0)\n",
      "Requirement already satisfied: click in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (from sacremoses==0.0.53) (8.1.7)\n",
      "Requirement already satisfied: joblib in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (from sacremoses==0.0.53) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /linux-data/miniconda3/envs/llm-edx-course/lib/python3.10/site-packages (from sacremoses==0.0.53) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Libraries:\n",
    "# [sacremoses](https://github.com/alvations/sacremoses) is for the translation model `Helsinki-NLP/opus-mt-en-es`\n",
    "\n",
    "%pip install sacremoses==0.0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8681f51c-543d-4253-957e-9062214c9b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A4000\n",
      "CPU times: user 1 s, sys: 240 ms, total: 1.24 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus > 0:\n",
    "    print(f\"GPUs available: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"There is no GPU available. Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef1b46-7dc5-4829-a4c3-fd45a0877cb0",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "Summarization can take two forms:\n",
    "* `extractive` (selecting representative excerpts from the text)\n",
    "* `abstractive` (generating novel text summaries)\n",
    "\n",
    "Here, we will use a model which does *abstractive* summarization.\n",
    "\n",
    "**Background reading**: The [Hugging Face summarization task page](https://huggingface.co/docs/transformers/tasks/summarization) lists model architectures which support summarization. The [summarization course chapter](https://huggingface.co/course/chapter7/5) provides a detailed walkthrough.\n",
    "\n",
    "In this section, we will use:\n",
    "* **Data**: [xsum](https://huggingface.co/datasets/xsum) dataset, which provides a set of BBC articles and summaries.\n",
    "* **Model**: [t5-small](https://huggingface.co/t5-small) model, which has 60 million parameters (242MB for PyTorch).  T5 is an encoder-decoder model created by Google which supports several tasks such as summarization, translation, Q&A, and text classification.\n",
    "\n",
    "For more details, see the [Google blog post](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html), [code on GitHub](https://github.com/google-research/text-to-text-transfer-transformer), or the [research paper](https://arxiv.org/pdf/1910.10683.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c6d70-de63-4676-b10b-bab1786368b1",
   "metadata": {},
   "source": [
    "### This dataset provides 3 columns:\n",
    "* `document`: the BBC article text\n",
    "* `summary`: a \"ground-truth\" summary --> Note how subjective this \"ground-truth\" is.  Is this the same summary you would write?  This a great example of how many LLM applications do not have obvious \"right\" answers.\n",
    "* `id`: article ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443ac678-b290-4041-86c4-56668edf48ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/linux-data/llm-course/data/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f517082f214ac28baea6c6bf3c2e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 204045\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11332\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11334\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    'xsum', version='1.2.0', cache_dir='data'\n",
    ")\n",
    "print(xsum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1249b08f-b8ca-4314-9aba-f0dfebaf7a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>35232142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>40143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>35951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>36266422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>38826984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>34540833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>20836172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>35932467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>40758845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>30358490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "5  Simone Favaro got the crucial try with the las...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  Belgian cyclist Demoitie died after a collisio...   \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...   \n",
       "9  The crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  Clean-up operations are continuing across the ...  35232142  \n",
       "1  Two tourist buses have been destroyed by fire ...  40143035  \n",
       "2  Lewis Hamilton stormed to pole position at the...  35951548  \n",
       "3  A former Lincolnshire Police officer carried o...  36266422  \n",
       "4  An armed man who locked himself into a room at...  38826984  \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...  34540833  \n",
       "6  A man with links to a car that was involved in...  20836172  \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...  35932467  \n",
       "8  Manchester City midfielder Ilkay Gundogan says...  40758845  \n",
       "9  A jogger has been hit by an unmarked police ca...  30358490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_sample = xsum_dataset['train'].select(range(10))\n",
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1732d8-af06-4ff1-b560-2e013fbf5051",
   "metadata": {},
   "source": [
    "#### We next use the Hugging Face `pipeline` tool to load a pre-trained model.  In this LLM pipeline constructor, we specify:\n",
    "* `task`: This first argument specifies the primary task.  See [Hugging Face tasks](https://huggingface.co/tasks) for more information.\n",
    "* `model`: This is the name of the pre-trained model from the [Hugging Face Hub](https://huggingface.co/models).\n",
    "* `min_length`, `max_length`: We want our generated summaries to be between these two token lengths.\n",
    "* `truncation`: Some input articles may be too long for the LLM to process.  Most LLMs have fixed limits on the length of input sequences.\n",
    "\n",
    "This option tells the pipeline to truncate the input if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a267a05b-f95b-4b49-9e3f-ed67577e5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    task='summarization',\n",
    "    model='t5-small',\n",
    "    min_length=20,\n",
    "    max_length=80,\n",
    "    truncation=True,\n",
    "    device=device,\n",
    "    model_kwargs={'cache_dir':'data'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4988cda1-8ef2-4ca0-9e0b-f1082b231cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to 1 article\n",
    "summarizer(xsum_sample['document'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08bcb77-f16c-43f9-8ad9-21e8f914136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to a batch of articles\n",
    "results = summarizer(xsum_sample['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082bb053-8da4-43ce-adae-8b010b68ec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastian Vettel will start third ahead of tea...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving psychiatric treatment at the c...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan will not be fit for the start of the ...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   generated_summary  \\\n",
       "0  the full cost of damage in Newton Stewart is s...   \n",
       "1  a fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Sebastian Vettel will start third ahead of tea...   \n",
       "3  the 67-year-old is accused of committing the o...   \n",
       "4  a man receiving psychiatric treatment at the c...   \n",
       "5  Gregor Townsend gave a debut to powerhouse win...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  the 25-year-old was hit by a motorbike during ...   \n",
       "8  gundogan will not be fit for the start of the ...   \n",
       "9  the crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...   \n",
       "6  A man with links to a car that was involved in...   \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...   \n",
       "8  Manchester City midfielder Ilkay Gundogan says...   \n",
       "9  A jogger has been hit by an unmarked police ca...   \n",
       "\n",
       "                                            document  \n",
       "0  The full cost of damage in Newton Stewart, one...  \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...  \n",
       "2  Ferrari appeared in a position to challenge un...  \n",
       "3  John Edward Bates, formerly of Spalding, Linco...  \n",
       "4  Patients and staff were evacuated from Cerahpa...  \n",
       "5  Simone Favaro got the crucial try with the las...  \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...  \n",
       "7  Belgian cyclist Demoitie died after a collisio...  \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...  \n",
       "9  The crash happened about 07:20 GMT at the junc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the generated summary side-by-side with the reference summary and original document.\n",
    "# We use Pandas to join the inputs and outputs together in a nice format.\n",
    "\n",
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({'summary_text' : 'generated_summary'}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        ['generated_summary', 'summary', 'document']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a28ed-9da2-4c8e-8c25-8fc97a4af4da",
   "metadata": {},
   "source": [
    "### Few-shot learning\n",
    "\n",
    "In few-shot learning tasks, you give the model an instruction, a few query-response examples of how to follow that instruction, and then a new query.  The model must generate the response for that new query.  This technique has pros and cons: it is very powerful and allows models to be reused for many more applications, but it can be finicky and require significant prompt engineering to get good and reliable results.\n",
    "\n",
    "**Background reading**: See the [Wikipedia page on few-shot learning](https://en.wikipedia.org/wiki/Few-shot_learning_&#40;natural_language_processing&#41;) or [this Hugging Face blog about few-shot learning](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api).\n",
    "\n",
    "In this section, we will use:\n",
    "* **Task**: Few-shot learning can be applied to many tasks.  Here, we will do sentiment analysis, which was covered earlier.  However, you will see how few-shot learning allows us to specify custom labels, whereas the previous model was tuned for a specific set of labels.  We will also show other (toy) tasks at the end.  In terms of the Hugging Face `task` specified in the `pipeline` constructor, few-shot learning is handled as a `text-generation` task.\n",
    "* **Data**: We use a few examples, including a tweet example from the blog post linked above.\n",
    "* **Model**: [gpt-neo-1.3B](https://huggingface.co/EleutherAI/gpt-neo-1.3B), a version of the GPT-Neo model discussed in the blog linked above.  It is a transformer model with 1.3 billion parameters developed by Eleuther AI.  For more details, see the [code on GitHub](https://github.com/EleutherAI/gpt-neo) or the [research paper](https://arxiv.org/abs/2204.06745)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2ea655-188b-43e9-9213-7c7d7c493f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.07 s, sys: 1.39 s, total: 8.46 s\n",
      "Wall time: 6.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# We will limit the response length for our few-shot learning tasks.\n",
    "\n",
    "few_shot_pipeline = pipeline (\n",
    "    task='text-generation',\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10,\n",
    "    device=device,\n",
    "    model_kwargs={'cache_dir': 'data'},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542c02c-065f-4629-80ea-b356203c5cc6",
   "metadata": {},
   "source": [
    "***Tip***: In the few-shot prompts below, we separate the examples with a special token \"###\" and use the same token to encourage the LLM to end its output after answering the query.  We will tell the pipeline to use that special token as the end-of-sequence (EOS) token below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f69e72a-bbf3-429c-a8c2-9ff71afdaeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21017\n"
     ]
    }
   ],
   "source": [
    "# Get the token ID for \"###\", which we will use as the EOS token below\n",
    "\n",
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]\n",
    "print(eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddef033-d46e-4f2b-ad14-57304637920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "    [Tweet]: \"This new music video was incredible\"\n",
      "    [Sentiment]:   \"Unbelievable\"\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "# Without any examples, the model output is inconsistent and usually incorrect\n",
    "\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "    [Tweet]: \"This new music video was incredible\"\n",
    "    [Sentiment]: \"\"\",\n",
    "    eos_token_id=eos_token_id\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66242359-34bd-4fe1-a92a-af6e26041f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "    [Tweet]: \"This is the link to the article\"\n",
      "    [Sentiment]: Neutral\n",
      "    ###\n",
      "    [Tweet]: \"This new music video was incredible\"\n",
      "    [Sentiment]:           \n"
     ]
    }
   ],
   "source": [
    "# With one example. the model may or may not get the answer right\n",
    "\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "    [Tweet]: \"This is the link to the article\"\n",
    "    [Sentiment]: Neutral\n",
    "    ###\n",
    "    [Tweet]: \"This new music video was incredible\"\n",
    "    [Sentiment]: \"\"\",\n",
    "    eos_token_id = eos_token_id\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c66534a8-b6ea-43cf-a1ff-4c7751bebff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "    [Tweet]: \"I hate it when my phone battery dies\"\n",
      "    [Sentiment]: \"Negative\"\n",
      "    ###\n",
      "    [Tweet]: \"My day has been nice\"\n",
      "    [Sentiment]: \"Positive\"\n",
      "    ###\n",
      "    [Tweet]: \"This is the link to the article\"\n",
      "    [Sentiment]: \"Neutral\"\n",
      "    ###\n",
      "    [Tweet]: \"This new music video was incredible\"\n",
      "    [Sentiment]: \"Positive\",\n",
      "    ###\n",
      "    [Tweet]: \"This place sucks\"\n",
      "    [Sentiment]: \"Negative\",\n",
      "    ###\n",
      "    [Tweet]: \"This new video clip was amazing\"\n",
      "    [Sentiment]:  \"Neutral\",\n",
      "    ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With 1 example for sentiment, the model is more likely to understand\n",
    "\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "    [Tweet]: \"I hate it when my phone battery dies\"\n",
    "    [Sentiment]: \"Negative\"\n",
    "    ###\n",
    "    [Tweet]: \"My day has been nice\"\n",
    "    [Sentiment]: \"Positive\"\n",
    "    ###\n",
    "    [Tweet]: \"This is the link to the article\"\n",
    "    [Sentiment]: \"Neutral\"\n",
    "    ###\n",
    "    [Tweet]: \"This new music video was incredible\"\n",
    "    [Sentiment]: \"Positive\",\n",
    "    ###\n",
    "    [Tweet]: \"This place sucks\"\n",
    "    [Sentiment]: \"Negative\",\n",
    "    ###\n",
    "    [Tweet]: \"This new video clip was amazing\"\n",
    "    [Sentiment]: \"\"\",\n",
    "    eos_token_id = eos_token_id\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7867c6-474d-431e-bb04-752473a61589",
   "metadata": {},
   "source": [
    "### Hugging Face APIs\n",
    " In this section, we dive into some more details on Hugging Face APIs.\n",
    "* Search and sampling to generate text\n",
    "* Auto* loaders for tokenizers and models\n",
    "* Model-specific loaders\n",
    "\n",
    "Recall the `xsum` dataset from the **Summarization** section above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24d9fc78-c46e-4d1b-8a2b-63895f33e962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>35232142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>40143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>35951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>36266422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>38826984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>34540833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>20836172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>35932467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>40758845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>30358490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "5  Simone Favaro got the crucial try with the las...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  Belgian cyclist Demoitie died after a collisio...   \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...   \n",
       "9  The crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  Clean-up operations are continuing across the ...  35232142  \n",
       "1  Two tourist buses have been destroyed by fire ...  40143035  \n",
       "2  Lewis Hamilton stormed to pole position at the...  35951548  \n",
       "3  A former Lincolnshire Police officer carried o...  36266422  \n",
       "4  An armed man who locked himself into a room at...  38826984  \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...  34540833  \n",
       "6  A man with links to a car that was involved in...  20836172  \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...  35932467  \n",
       "8  Manchester City midfielder Ilkay Gundogan says...  40758845  \n",
       "9  A jogger has been hit by an unmarked police ca...  30358490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68974c3a-269f-499c-a6ae-96c96987901f",
   "metadata": {},
   "source": [
    "#### Search and sampling in inference\n",
    "You may see parameters like `num_beams`, `do_sample`, etc. specified in Hugging Face pipelines.  These are inference configurations.\n",
    "\n",
    "LLMs work by predicting (generating) the next token, then the next, and so on.  The goal is to generate a high probability sequence of tokens, which is essentially a search through the (enormous) space of potential sequences.\n",
    "\n",
    "To do this search, LLMs use one of two main methods:\n",
    "* **Search**: Given the tokens generated so far, pick the next most likely token in a \"search.\"\n",
    "  * **Greedy search** (default): Pick the single next most likely token in a greedy search.\n",
    "  * **Beam search**: Greedy search can be extended via beam search, which searches down several sequence paths, via the parameter `num_beams`.\n",
    "* **Sampling**: Given the tokens generated so far, pick the next token by sampling from the predicted distribution of tokens.\n",
    "  * **Top-K sampling**: The parameter `top_k` modifies sampling by limiting it to the `k` most likely tokens.\n",
    "  * **Top-p sampling**: The parameter `top_p` modifies sampling by limiting it to the most likely tokens up to probability mass `p`.\n",
    "\n",
    "You can toggle between search and sampling via parameter `do_sample`.\n",
    "\n",
    "For more background on search and sampling, see [this Hugging Face blog post](https://huggingface.co/blog/how-to-generate).\n",
    "\n",
    "We will illustrate these various options below using our summarization pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485ebf24-2682-4342-a851-27170daa3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We previously called the summarization pipeline using the default inference configuration.\n",
    "# This does greedy search.\n",
    "\n",
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c3f432a-a06d-44a5-be6a-de4c5761b659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "# This takes longer to run, but it might find a better (more likely) sequence of text.\n",
    "\n",
    "summarizer(xsum_sample[\"document\"][0], num_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a710625d-35d4-4b78-b901-0652845ce772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'many businesses and householders were affected by flooding in Newton Stewart . the water breached a retaining wall, flooding many commercial properties . a flood alert remains in place across the Borders because of the constant rain .'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8910ccd1-b9f3-45dc-99c9-f1b5c44c4dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample = True, top_k = 10, top_p = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e727b8-6b7b-4513-96c6-e077275d15ac",
   "metadata": {},
   "source": [
    "#### Auto* loaders for tokenizers and models\n",
    "\n",
    "We have already seen the `dataset` and `pipeline` abstractions from Hugging Face.  While a `pipeline` is a quick way to set up an LLM for a given task, the slightly lower-level abstractions `model` and `tokenizer` permit a bit more control over options.  We will show how to use those briefly, following this pattern:\n",
    "\n",
    "* Given input articles.\n",
    "* Tokenize them (converting to token indices).\n",
    "* Apply the model on the tokenized data to generate summaries (represented as token indices).\n",
    "* Decode the summaries into human-readable text.\n",
    "\n",
    "We will first look at the [Auto* classes](https://huggingface.co/docs/transformers/model_doc/auto) for tokenizers and model types which can simplify loading pre-trained tokenizers and models.\n",
    "\n",
    "API docs:\n",
    "* [AutoTokenizer](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer)\n",
    "* [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d0af9f-ca90-48e3-a400-3382bc9ce56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    't5-small',\n",
    "    cache_dir = 'data'\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    't5-small',\n",
    "    cache_dir = 'data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e7e101b-86ad-4b8c-b0bc-d0a051aaae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: The full cost of damage in Newton S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: A fire alarm went off at the Holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarize: Ferrari appeared in a position to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summarize: John Edward Bates, formerly of Spal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summarize: Patients and staff were evacuated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize: Simone Favaro got the crucial try w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>summarize: Veronica Vanessa Chango-Alverez, 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>summarize: Belgian cyclist Demoitie died after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>summarize: Gundogan, 26, told BBC Sport he \"ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>summarize: The crash happened about 07:20 GMT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             prompts\n",
       "0  summarize: The full cost of damage in Newton S...\n",
       "1  summarize: A fire alarm went off at the Holida...\n",
       "2  summarize: Ferrari appeared in a position to c...\n",
       "3  summarize: John Edward Bates, formerly of Spal...\n",
       "4  summarize: Patients and staff were evacuated f...\n",
       "5  summarize: Simone Favaro got the crucial try w...\n",
       "6  summarize: Veronica Vanessa Chango-Alverez, 31...\n",
       "7  summarize: Belgian cyclist Demoitie died after...\n",
       "8  summarize: Gundogan, 26, told BBC Sport he \"ca...\n",
       "9  summarize: The crash happened about 07:20 GMT ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\n",
    "\n",
    "articles = list(map(\n",
    "    lambda article: \"summarize: \" + article,\n",
    "    xsum_sample[\"document\"]\n",
    "))\n",
    "\n",
    "display(pd.DataFrame(articles, columns=[\"prompts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63a0fef0-ef11-40da-9ea7-3336e2687ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "tensor([[21603,    10,    37,  ...,     0,     0,     0],\n",
      "        [21603,    10,    71,  ...,     0,     0,     0],\n",
      "        [21603,    10, 21945,  ..., 18002,    21,     1],\n",
      "        ...,\n",
      "        [21603,    10, 21768,  ...,     0,     0,     0],\n",
      "        [21603,    10,  9982,  ...,     0,     0,     0],\n",
      "        [21603,    10,    37,  ...,     0,     0,     0]])\n",
      "attention_mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input\n",
    "\n",
    "inputs = tokenizer(articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "print(\"input_ids:\")\n",
    "print(inputs['input_ids'])\n",
    "print(\"attention_mask:\")\n",
    "print(inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde1499-279e-4a73-928b-882cabe11d10",
   "metadata": {},
   "source": [
    "# Generate summaries\n",
    "\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask = inputs.attention_mask,\n",
    "    num_beams = 2, min_length = 0, max_length = 40\n",
    ")\n",
    "\n",
    "print(summary_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3509055-bde6-4bcd-a7d8-cd211c82bccb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Decode the generated summaries\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m decoded_summaries \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\u001b[43msummary\u001b[49m, skip_special_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m display(pd\u001b[38;5;241m.\u001b[39mDataFrame(decoded_summaries, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_summaries\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "# Decode the generated summaries\n",
    "\n",
    "decoded_summaries = tokenizer.batch_decode(summary, skip_special_tokens = True)\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165b2ef-a2aa-4277-a267-17f878f3ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_time = time.strftime(\"%H:%M:%S\", time.gmtime(total_time))\n",
    "print(\"Script execution time:\", total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a145ce-fc5e-4735-847a-30792d458f8e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We've covered some common LLM applications and seen how to get started with them quickly using pre-trained models from the Hugging Face Hub.  We've also see how to tweak some configurations.\n",
    "\n",
    "But how did we find those models for our tasks?  In the lab, you will find new pre-trained models for tasks, using the Hugging Face Hub.  You will also explore tweaking model configurations to gain intuition about their effects.\n",
    "\n",
    "<hr>\n",
    "\n",
    " &copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
